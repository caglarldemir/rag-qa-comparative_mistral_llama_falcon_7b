{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12619895,"sourceType":"datasetVersion","datasetId":7973196}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-31T10:13:39.135218Z","iopub.status.idle":"2025-07-31T10:13:39.135441Z","shell.execute_reply.started":"2025-07-31T10:13:39.135337Z","shell.execute_reply":"2025-07-31T10:13:39.135347Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\"\"\"!pip uninstall -y langchain langchain-core langchain-community langchain-huggingface\n\n!pip install langchain==0.1.14 \\\n            langchain-core==0.1.33 \\\n            langchain-community==0.0.23 \\\n            langchain-huggingface==0.0.5\n\n!pip install -U pydantic\n\n!pip install langchain_community","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:19:52.597480Z","iopub.execute_input":"2025-07-30T15:19:52.597883Z","iopub.status.idle":"2025-07-30T15:19:52.605357Z","shell.execute_reply.started":"2025-07-30T15:19:52.597856Z","shell.execute_reply":"2025-07-30T15:19:52.604141Z"}},"outputs":[{"traceback":["\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_271/3654565852.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    \"\"\"\"\"\"!pip uninstall -y langchain langchain-core langchain-community langchain-huggingface\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"],"ename":"SyntaxError","evalue":"invalid syntax (3654565852.py, line 1)","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"!pip uninstall -y transformers sentence-transformers peft\n!pip install transformers==4.41.2 sentence-transformers==2.6.1 peft==0.10.0\n# (Optional, only if you see a warning about HuggingFaceEmbeddings)\n!pip install -U langchain-huggingface\n!pip install langchain_community\n!pip install chromadb\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T10:14:06.868627Z","iopub.execute_input":"2025-07-31T10:14:06.869267Z","iopub.status.idle":"2025-07-31T10:16:39.040585Z","shell.execute_reply.started":"2025-07-31T10:14:06.869244Z","shell.execute_reply":"2025-07-31T10:16:39.039871Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: transformers 4.52.4\nUninstalling transformers-4.52.4:\n  Successfully uninstalled transformers-4.52.4\nFound existing installation: sentence-transformers 4.1.0\nUninstalling sentence-transformers-4.1.0:\n  Successfully uninstalled sentence-transformers-4.1.0\nFound existing installation: peft 0.15.2\nUninstalling peft-0.15.2:\n  Successfully uninstalled peft-0.15.2\nCollecting transformers==4.41.2\n  Downloading transformers-4.41.2-py3-none-any.whl.metadata (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting sentence-transformers==2.6.1\n  Downloading sentence_transformers-2.6.1-py3-none-any.whl.metadata (11 kB)\nCollecting peft==0.10.0\n  Downloading peft-0.10.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (0.33.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (2.32.4)\nCollecting tokenizers<0.20,>=0.19 (from transformers==4.41.2)\n  Downloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.41.2) (4.67.1)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.6.1) (2.6.0+cu124)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.6.1) (1.2.2)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.6.1) (1.15.3)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==2.6.1) (11.2.1)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (7.0.0)\nRequirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft==0.10.0) (1.8.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (2025.5.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers==4.41.2) (1.1.5)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.41.2) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.41.2) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.41.2) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.41.2) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.41.2) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers==4.41.2) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.6.1) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.6.1) (3.1.6)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers==2.6.1)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers==2.6.1)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers==2.6.1)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers==2.6.1)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers==2.6.1)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers==2.6.1)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers==2.6.1)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers==2.6.1)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers==2.6.1)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.6.1) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.6.1) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.6.1) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers==2.6.1)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.6.1) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==2.6.1) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers==2.6.1) (1.3.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.41.2) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.41.2) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.41.2) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.41.2) (2025.6.15)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers==2.6.1) (1.5.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers==2.6.1) (3.6.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers==2.6.1) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.41.2) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers==4.41.2) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers==4.41.2) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers==4.41.2) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers==4.41.2) (2024.2.0)\nDownloading transformers-4.41.2-py3-none-any.whl (9.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading sentence_transformers-2.6.1-py3-none-any.whl (163 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.3/163.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading peft-0.10.0-py3-none-any.whl (199 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tokenizers-0.19.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tokenizers, nvidia-cusolver-cu12, transformers, sentence-transformers, peft\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: tokenizers\n    Found existing installation: tokenizers 0.21.2\n    Uninstalling tokenizers-0.21.2:\n      Successfully uninstalled tokenizers-0.21.2\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 peft-0.10.0 sentence-transformers-2.6.1 tokenizers-0.19.1 transformers-4.41.2\nCollecting langchain-huggingface\n  Downloading langchain_huggingface-0.3.1-py3-none-any.whl.metadata (996 bytes)\nCollecting langchain-core<1.0.0,>=0.3.70 (from langchain-huggingface)\n  Downloading langchain_core-0.3.72-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.19.1)\nCollecting huggingface-hub>=0.33.4 (from langchain-huggingface)\n  Downloading huggingface_hub-0.34.3-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (2025.5.1)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (2.32.4)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (1.1.5)\nRequirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.4.1)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (8.5.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.33)\nRequirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.11.7)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.0.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.10.18)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.23.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (2025.6.15)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (4.9.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.16.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.3.1)\nDownloading langchain_huggingface-0.3.1-py3-none-any.whl (27 kB)\nDownloading huggingface_hub-0.34.3-py3-none-any.whl (558 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m558.8/558.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading langchain_core-0.3.72-py3-none-any.whl (442 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.8/442.8 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: huggingface-hub, langchain-core, langchain-huggingface\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.33.1\n    Uninstalling huggingface-hub-0.33.1:\n      Successfully uninstalled huggingface-hub-0.33.1\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.66\n    Uninstalling langchain-core-0.3.66:\n      Successfully uninstalled langchain-core-0.3.66\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.5.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed huggingface-hub-0.34.3 langchain-core-0.3.72 langchain-huggingface-0.3.1\nCollecting langchain_community\n  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.72)\nRequirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.26)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.41)\nRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.4)\nRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.12.13)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (8.5.0)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\nRequirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.1)\nCollecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\nRequirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (1.26.4)\nRequirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.7.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.6.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.2)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (0.3.8)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain_community) (2.11.7)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (1.33)\nRequirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (4.14.0)\nRequirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain_community) (25.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (3.10.18)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain_community) (0.23.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain_community) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain_community) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain_community) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain_community) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain_community) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.26.2->langchain_community) (2.4.1)\nCollecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.6.15)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.3)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (4.9.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (0.16.0)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain_community) (3.0.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain_community) (2.33.2)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain_community) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.26.2->langchain_community) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.26.2->langchain_community) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.26.2->langchain_community) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.26.2->langchain_community) (2024.2.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.3.1)\nDownloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\nDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\nInstalling collected packages: python-dotenv, httpx-sse, pydantic-settings, langchain_community\nSuccessfully installed httpx-sse-0.4.1 langchain_community-0.3.27 pydantic-settings-2.10.1 python-dotenv-1.1.1\nCollecting chromadb\n  Downloading chromadb-1.0.15-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\nRequirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\nRequirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.11.7)\nCollecting pybase64>=1.4.1 (from chromadb)\n  Downloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\nRequirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.3)\nRequirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.26.4)\nCollecting posthog<6.0.0,>=2.4.0 (from chromadb)\n  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\nRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.14.0)\nCollecting onnxruntime>=1.14.1 (from chromadb)\n  Downloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.6 kB)\nCollecting opentelemetry-api>=1.2.0 (from chromadb)\n  Downloading opentelemetry_api-1.36.0-py3-none-any.whl.metadata (1.5 kB)\nCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl.metadata (2.4 kB)\nCollecting opentelemetry-sdk>=1.2.0 (from chromadb)\n  Downloading opentelemetry_sdk-1.36.0-py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.19.1)\nCollecting pypika>=0.48.9 (from chromadb)\n  Downloading PyPika-0.48.9.tar.gz (67 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\nRequirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\nRequirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\nRequirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.73.1)\nCollecting bcrypt>=4.0.1 (from chromadb)\n  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.16.0)\nCollecting kubernetes>=28.1.0 (from chromadb)\n  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (8.5.0)\nRequirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\nCollecting mmh3>=4.0.1 (from chromadb)\n  Downloading mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\nRequirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.18)\nRequirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (14.0.0)\nRequirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.24.0)\nRequirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (25.0)\nRequirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.6.15)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\nRequirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.25.1)\nRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\nRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\nRequirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.40.3)\nRequirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.4)\nRequirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\nRequirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\nRequirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.5.0)\nCollecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (2025.2.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (2022.2.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.22.5->chromadb) (2.4.1)\nCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\nRequirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\nRequirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\nRequirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\nCollecting opentelemetry-exporter-otlp-proto-common==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl.metadata (1.8 kB)\nCollecting opentelemetry-proto==1.36.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n  Downloading opentelemetry_proto-1.36.0-py3-none-any.whl.metadata (2.3 kB)\nCollecting protobuf (from onnxruntime>=1.14.1->chromadb)\n  Downloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\nCollecting opentelemetry-semantic-conventions==0.57b0 (from opentelemetry-sdk>=1.2.0->chromadb)\n  Downloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl.metadata (2.4 kB)\nCollecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.4.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.34.3)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\nCollecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\nRequirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\nCollecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\nRequirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.5.1)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.1.5)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.2)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.5->chromadb) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.22.5->chromadb) (2022.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.22.5->chromadb) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.22.5->chromadb) (2024.2.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.22.5->chromadb) (2024.2.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\nDownloading chromadb-1.0.15-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m97.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading mmh3-5.2.0-cp311-cp311-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading onnxruntime-1.22.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading opentelemetry_api-1.36.0-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.36.0-py3-none-any.whl (18 kB)\nDownloading opentelemetry_exporter_otlp_proto_common-1.36.0-py3-none-any.whl (18 kB)\nDownloading opentelemetry_proto-1.36.0-py3-none-any.whl (72 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_sdk-1.36.0-py3-none-any.whl (119 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_semantic_conventions-0.57b0-py3-none-any.whl (201 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading posthog-5.4.0-py3-none-any.whl (105 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pybase64-1.4.2-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\nDownloading durationpy-0.10-py3-none-any.whl (3.9 kB)\nDownloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading protobuf-6.31.1-cp39-abi3-manylinux2014_x86_64.whl (321 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.1/321.1 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pypika\n  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=dec605888a994ed3d11888d6460953ca30733b5488267bb39c54a17c26c97fb4\n  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\nSuccessfully built pypika\nInstalling collected packages: pypika, durationpy, uvloop, pybase64, protobuf, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, posthog, opentelemetry-proto, opentelemetry-api, coloredlogs, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, kubernetes, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, onnxruntime, chromadb\n  Attempting uninstall: protobuf\n    Found existing installation: protobuf 3.20.3\n    Uninstalling protobuf-3.20.3:\n      Successfully uninstalled protobuf-3.20.3\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.8.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngoogle-api-core 1.34.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5, but you have protobuf 6.31.1 which is incompatible.\ngoogle-cloud-translate 3.12.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 6.31.1 which is incompatible.\npandas-gbq 0.29.1 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ngoogle-ai-generativelanguage 0.6.15 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 6.31.1 which is incompatible.\ngoogle-cloud-storage 2.19.0 requires google-api-core<3.0.0dev,>=2.15.0, but you have google-api-core 1.34.1 which is incompatible.\ndataproc-spark-connect 0.7.5 requires google-api-core>=2.19, but you have google-api-core 1.34.1 which is incompatible.\ntensorflow 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.31.1 which is incompatible.\nbigframes 2.8.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.8.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.15 coloredlogs-15.0.1 durationpy-0.10 httptools-0.6.4 humanfriendly-10.0 kubernetes-33.1.0 mmh3-5.2.0 onnxruntime-1.22.1 opentelemetry-api-1.36.0 opentelemetry-exporter-otlp-proto-common-1.36.0 opentelemetry-exporter-otlp-proto-grpc-1.36.0 opentelemetry-proto-1.36.0 opentelemetry-sdk-1.36.0 opentelemetry-semantic-conventions-0.57b0 posthog-5.4.0 protobuf-6.31.1 pybase64-1.4.2 pypika-0.48.9 uvloop-0.21.0 watchfiles-1.1.0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"hglm\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T10:16:39.041873Z","iopub.execute_input":"2025-07-31T10:16:39.042405Z","iopub.status.idle":"2025-07-31T10:16:39.176738Z","shell.execute_reply.started":"2025-07-31T10:16:39.042380Z","shell.execute_reply":"2025-07-31T10:16:39.176043Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from huggingface_hub import login\nlogin(secret_value_0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T10:16:39.177350Z","iopub.execute_input":"2025-07-31T10:16:39.177565Z","iopub.status.idle":"2025-07-31T10:16:39.686469Z","shell.execute_reply.started":"2025-07-31T10:16:39.177549Z","shell.execute_reply":"2025-07-31T10:16:39.685952Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install langchain-huggingface\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-30T15:20:40.073311Z","iopub.execute_input":"2025-07-30T15:20:40.073577Z","iopub.status.idle":"2025-07-30T15:20:43.556188Z","shell.execute_reply.started":"2025-07-30T15:20:40.073558Z","shell.execute_reply":"2025-07-30T15:20:43.555081Z"}},"outputs":[{"name":"stdout","text":"Collecting langchain-huggingface\n  Using cached langchain_huggingface-0.3.1-py3-none-any.whl.metadata (996 bytes)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.70 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.3.72)\nRequirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.21.4)\nRequirement already satisfied: huggingface-hub>=0.33.4 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.34.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (2025.5.1)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (6.0.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (2.32.4)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (4.67.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (4.14.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (1.1.5)\nRequirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.4.1)\nRequirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (8.5.0)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.33)\nRequirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.11.7)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.0.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.10.18)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.23.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (2025.6.15)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (4.9.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.16.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.3.1)\nUsing cached langchain_huggingface-0.3.1-py3-none-any.whl (27 kB)\nInstalling collected packages: langchain-huggingface\nSuccessfully installed langchain-huggingface-0.3.1\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport time\nfrom langchain_community.vectorstores import Chroma\nfrom langchain_huggingface import HuggingFaceEmbeddings\nfrom langchain_community.document_loaders import PyPDFLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_huggingface import HuggingFacePipeline\nfrom transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n\n# Step 1: Load and split PDFs\ndef load_pdf_folder(folder_path):\n    start_time = time.time()\n    documents = []\n    for file in os.listdir(folder_path):\n        if file.endswith(\".pdf\"):\n            loader = PyPDFLoader(os.path.join(folder_path, file))\n            documents.extend(loader.load())\n    print(f\"📄 Loaded {len(documents)} documents in {time.time() - start_time:.2f} seconds\")\n    return documents\n\n# Step 2: Split into chunks\ndef split_docs(documents):\n    start_time = time.time()\n    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n    chunks = splitter.split_documents(documents)\n    print(f\"✂️  Split into {len(chunks)} chunks in {time.time() - start_time:.2f} seconds\")\n    return chunks\n\n# Step 3: Embed documents\ndef create_vectorstore(docs):\n    start_time = time.time()\n    embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n    db = Chroma.from_documents(docs, embedding)\n    print(f\"🔍 Created vectorstore in {time.time() - start_time:.2f} seconds\")\n    return db\n\n# Step 4: Load Mistral 7B (recommended replacement)\ndef load_mistral_model(model_id=\"mistralai/Mistral-7B-Instruct-v0.2\"):\n    start_time = time.time()\n    tokenizer = AutoTokenizer.from_pretrained(model_id)\n    model = AutoModelForCausalLM.from_pretrained(\n        model_id,\n        device_map=\"auto\",\n        torch_dtype=\"auto\"\n    )\n    pipe = pipeline(\n        \"text-generation\",\n        model=model,\n        tokenizer=tokenizer,\n        max_new_tokens=256,\n        do_sample=True,\n        temperature=0.7,\n        top_p=0.9,\n        repetition_penalty=1.1\n    )\n    llm = HuggingFacePipeline(pipeline=pipe)\n    print(f\"🤖 Loaded Mistral 7B in {time.time() - start_time:.2f} seconds\")\n    return llm\n\n# Step 5: Answer a question using RAG\ndef ask_question(llm, db, question):\n    start_time = time.time()\n    relevant_docs = db.similarity_search(question, k=2)\n    \n    context_parts = []\n    for doc in relevant_docs:\n        clean_text = doc.page_content.strip()\n        if len(clean_text) > 500:\n            clean_text = clean_text[:500] + \"...\"\n        context_parts.append(clean_text)\n    \n    context = \"\\n\\n\".join(context_parts)\n    \n    prompt = f\"\"\"You are a helpful assistant. Based on the following context, answer the question concisely.\n\nContext:\n{context}\n\nQuestion: {question}\nAnswer:\"\"\"\n    \n    response = llm.invoke(prompt)\n\n    response_text = str(response)\n\n    # Extract only the answer part, without the context or prompt\n    answer_start = response_text.find(\"Answer:\")\n    if answer_start != -1:\n        answer = response_text[answer_start + len(\"Answer:\"):].strip()\n    else:\n        answer = response_text.strip()\n\n    # Clean out any remaining prompt artifacts just in case\n    for artifact in [\"Context:\", \"Question:\", \"Answer the question using the context below.\"]:\n        answer = answer.replace(artifact, \"\")\n    answer = answer.strip()\n    print(f\"⏱️  Generated answer in {time.time() - start_time:.2f} seconds\")\n    \n    return answer\n\n\n\n# Step 6: Chatbot loop\ndef chatbot(llm, db):\n    print(\"\\n\" + \"=\"*80)\n    print(\"🤖 RAG CHATBOT - Ask questions about your documents!\")\n    print(\"💡 Type 'quit' or 'exit' to end the conversation\")\n    print(\"=\"*80)\n\n    question_count = 0\n\n    while True:\n        print(\"\\n\" + \"-\"*50)\n        user_input = input(\"❓ Your question: \").strip()\n\n        if user_input.lower() in ['quit', 'exit', 'q', 'bye']:\n            print(\"\\n👋 Thanks for using the RAG Chatbot! Goodbye!\")\n            break\n\n        if not user_input:\n            print(\"⚠️  Please enter a question.\")\n            continue\n\n        question_count += 1\n        print(f\"\\n🔍 Processing question #{question_count}...\")\n\n        try:\n            answer = ask_question(llm, db, user_input)\n            print(f\"\\n💡 Answer #{question_count}:\")\n            print(\"-\" * 40)\n            print(answer)\n            print(\"-\" * 40)\n        except Exception as e:\n            print(f\"❌ Error generating answer: {str(e)}\")\n\n# === MAIN ===\npdf_folder_path = \"/kaggle/input/documents/\"  # Update if needed\n\nprint(\"🚀 Starting RAG Pipeline...\")\ntotal_start_time = time.time()\n\nprint(\"🔍 Loading PDFs...\")\ndocs = load_pdf_folder(pdf_folder_path)\nchunks = split_docs(docs)\n\nprint(\"📚 Creating vectorstore...\")\ndb = create_vectorstore(chunks)\n\nprint(\"🚀 Loading Mistral model...\")\nllm = load_mistral_model()\n\nprint(f\"✅ Setup completed in {time.time() - total_start_time:.2f} seconds\")\n\nchatbot(llm, db)\n\nprint(f\"\\n🎉 Total session time: {time.time() - total_start_time:.2f} seconds\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T11:05:00.670280Z","iopub.execute_input":"2025-07-31T11:05:00.670602Z","iopub.status.idle":"2025-07-31T11:10:15.555148Z","shell.execute_reply.started":"2025-07-31T11:05:00.670579Z","shell.execute_reply":"2025-07-31T11:10:15.554437Z"}},"outputs":[{"name":"stdout","text":"🚀 Starting RAG Pipeline...\n🔍 Loading PDFs...\n📄 Loaded 153 documents in 9.98 seconds\n✂️  Split into 2103 chunks in 0.05 seconds\n📚 Creating vectorstore...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"🔍 Created vectorstore in 7.37 seconds\n🚀 Loading Mistral model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.10k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3c605136ff64c2086cf79f2ec96ccff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cba9497ec52e4d0aa73e2cd843819f5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d887a1da7faa4097a47104bd8c1d56f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5dd2b44930d4e11afeee5cdacc36453"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/596 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c4db67e7a98548a1928d4d08d9f4749d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a3c561fcaa64710919462e53136006f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0043b6af012340c9979b3f250ab7b46a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e0ea2d555b440eb982a339f2ddfdbb0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cdfd1148acd04c7da951aa8dfd3ca27c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab23e30afd4f4820812aaf838a60413d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3605512e342f449995d35083d3d20b66"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8529e8268f8d4ea7a068e02a384d3e0e"}},"metadata":{}},{"name":"stdout","text":"🤖 Loaded Mistral 7B in 165.29 seconds\n✅ Setup completed in 182.71 seconds\n\n================================================================================\n🤖 RAG CHATBOT - Ask questions about your documents!\n💡 Type 'quit' or 'exit' to end the conversation\n================================================================================\n\n--------------------------------------------------\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"❓ Your question:  What is co-branding? \n"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n🔍 Processing question #1...\n⏱️  Generated answer in 20.90 seconds\n\n💡 Answer #1:\n----------------------------------------\nCo-branding is a marketing strategy where a host brand teams up with one or more participant brands to share their assets and create a new product or marketing campaign.\n----------------------------------------\n\n--------------------------------------------------\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"❓ Your question:  What is luxury co-branding?\n"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n🔍 Processing question #2...\n⏱️  Generated answer in 30.32 seconds\n\n💡 Answer #2:\n----------------------------------------\nLuxury co-branding refers to a marketing strategy where a luxury brand partners with a mass brand to create a product or service offering. Despite its prevalence in the marketplace, there is limited academic research on this topic. The exceptions include a study by Rollet et al. (2013).\n----------------------------------------\n\n--------------------------------------------------\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"❓ Your question:  Which factors affect brand competitiveness?\n"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n🔍 Processing question #3...\n⏱️  Generated answer in 20.12 seconds\n\n💡 Answer #3:\n----------------------------------------\nBrand competitiveness is influenced by a combination of factors including a brand's uniqueness based on internal features, external image, and regional characteristics, as well as its market share and value creation capability.\n----------------------------------------\n\n--------------------------------------------------\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"❓ Your question:  quit\n"},{"name":"stdout","text":"\n👋 Thanks for using the RAG Chatbot! Goodbye!\n\n🎉 Total session time: 314.87 seconds\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import os\nimport time\nfrom langchain_community.vectorstores import Chroma\nfrom langchain_huggingface import HuggingFaceEmbeddings\nfrom langchain_community.document_loaders import PyPDFLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_huggingface import HuggingFacePipeline\nfrom transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n\n# Step 1: Load and split PDFs\ndef load_pdf_folder(folder_path):\n    start_time = time.time()\n    documents = []\n    for file in os.listdir(folder_path):\n        if file.endswith(\".pdf\"):\n            loader = PyPDFLoader(os.path.join(folder_path, file))\n            documents.extend(loader.load())\n    print(f\"📄 Loaded {len(documents)} documents in {time.time() - start_time:.2f} seconds\")\n    return documents\n\n# Step 2: Split into chunks\ndef split_docs(documents):\n    start_time = time.time()\n    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n    chunks = splitter.split_documents(documents)\n    print(f\"✂️  Split into {len(chunks)} chunks in {time.time() - start_time:.2f} seconds\")\n    return chunks\n\n# Step 3: Embed documents\ndef create_vectorstore(docs):\n    start_time = time.time()\n    embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n    db = Chroma.from_documents(docs, embedding)\n    print(f\"🔍 Created vectorstore in {time.time() - start_time:.2f} seconds\")\n    return db\n\n# Step 4: Load Falcon 7B Instruct\ndef load_falcon_model(model_id=\"tiiuae/falcon-7b-instruct\"):\n    start_time = time.time()\n    tokenizer = AutoTokenizer.from_pretrained(model_id)\n    model = AutoModelForCausalLM.from_pretrained(\n        model_id,\n        device_map=\"auto\",\n        torch_dtype=\"auto\",\n        trust_remote_code=True\n    )\n    pipe = pipeline(\n        \"text-generation\",\n        model=model,\n        tokenizer=tokenizer,\n        max_new_tokens=256,\n        do_sample=True,\n        temperature=0.7,\n        top_p=0.9,\n        repetition_penalty=1.1\n    )\n    llm = HuggingFacePipeline(pipeline=pipe)\n    print(f\"🤖 Loaded Falcon 7B Instruct in {time.time() - start_time:.2f} seconds\")\n    return llm\n\n# Step 5: Ask question function (clean answer only)\ndef ask_question(llm, db, question):\n    start_time = time.time()\n    relevant_docs = db.similarity_search(question, k=2)\n    \n    context_parts = []\n    for doc in relevant_docs:\n        clean_text = doc.page_content.strip()\n        if len(clean_text) > 500:\n            clean_text = clean_text[:500] + \"...\"\n        context_parts.append(clean_text)\n    \n    context = \"\\n\\n\".join(context_parts)\n    \n    prompt = f\"\"\"You are a helpful assistant. Based on the following context, answer the question concisely.\n\nContext:\n{context}\n\nQuestion: {question}\nAnswer:\"\"\"\n    \n    response = llm.invoke(prompt)\n    response_text = str(response)\n    \n    # Extract answer after \"Answer:\" label if present\n    answer_start = response_text.find(\"Answer:\")\n    if answer_start != -1:\n        answer = response_text[answer_start + len(\"Answer:\"):].strip()\n    else:\n        answer = response_text.strip()\n    \n    # Clean any residual artifacts\n    for artifact in [\"Context:\", \"Question:\", \"Answer the question using the context below.\"]:\n        answer = answer.replace(artifact, \"\")\n    answer = answer.strip()\n    \n    print(f\"⏱️ Generated answer in {time.time() - start_time:.2f} seconds\")\n    return answer\n\n# Step 6: Chatbot loop for Falcon + vectorstore\ndef chatbot(llm, db):\n    print(\"\\n\" + \"=\"*80)\n    print(\"🤖 Falcon 7B RAG Chatbot\")\n    print(\"💡 Type 'quit' or 'exit' to end the session\")\n    print(\"=\"*80)\n\n    question_count = 0\n\n    while True:\n        user_input = input(\"\\n❓ Your question: \").strip()\n\n        if user_input.lower() in ['quit', 'exit', 'q', 'bye']:\n            print(\"\\n👋 Thanks for using the Falcon RAG Chatbot! Goodbye!\")\n            break\n\n        if not user_input:\n            print(\"⚠️ Please enter a question.\")\n            continue\n\n        question_count += 1\n        print(f\"\\n🔍 Processing question #{question_count}...\")\n        try:\n            answer = ask_question(llm, db, user_input)\n            print(f\"\\n💡 Answer #{question_count}:\")\n            print(\"-\" * 40)\n            print(answer)\n            print(\"-\" * 40)\n        except Exception as e:\n            print(f\"❌ Error generating answer: {str(e)}\")\n\n# === MAIN ===\nif __name__ == \"__main__\":\n    pdf_folder_path = \"/kaggle/input/documents/\"  # update as needed\n\n    print(\"🚀 Starting RAG Pipeline...\")\n    total_start_time = time.time()\n\n    print(\"🔍 Loading PDFs...\")\n    docs = load_pdf_folder(pdf_folder_path)\n    chunks = split_docs(docs)\n\n    print(\"📚 Creating vectorstore...\")\n    db = create_vectorstore(chunks)\n\n    print(\"🚀 Loading Falcon 7B model...\")\n    llm = load_falcon_model()\n\n    print(f\"✅ Setup completed in {time.time() - total_start_time:.2f} seconds\")\n\n    chatbot(llm, db)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T11:21:54.352361Z","iopub.execute_input":"2025-07-31T11:21:54.353126Z","iopub.status.idle":"2025-07-31T11:25:27.814883Z","shell.execute_reply.started":"2025-07-31T11:21:54.353096Z","shell.execute_reply":"2025-07-31T11:25:27.814153Z"}},"outputs":[{"name":"stdout","text":"🚀 Starting RAG Pipeline...\n🔍 Loading PDFs...\n📄 Loaded 153 documents in 9.46 seconds\n✂️  Split into 2103 chunks in 0.05 seconds\n📚 Creating vectorstore...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"🔍 Created vectorstore in 7.34 seconds\n🚀 Loading Falcon 7B model...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65cd1913e74348a785cf453a1611bfa3"}},"metadata":{}},{"name":"stdout","text":"🤖 Loaded Falcon 7B Instruct in 59.48 seconds\n✅ Setup completed in 76.33 seconds\n\n================================================================================\n🤖 Falcon 7B RAG Chatbot\n💡 Type 'quit' or 'exit' to end the session\n================================================================================\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\n❓ Your question:  What is co-branding?\n"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n🔍 Processing question #1...\n⏱️ Generated answer in 10.06 seconds\n\n💡 Answer #1:\n----------------------------------------\nCo-branding is a marketing strategy in which two or more companies work together to create a new product or service that can benefit each of their individual brands.\n----------------------------------------\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\n❓ Your question:  What is luxury co-branding?\n"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n🔍 Processing question #2...\n⏱️ Generated answer in 8.28 seconds\n\n💡 Answer #2:\n----------------------------------------\nLuxury co-branding is the marketing practice of a high-end brand associating with a less prestigious brand or product to enhance the image of both.\n----------------------------------------\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\n❓ Your question:  Which factors affect brand competitiveness?\n"},{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"\n🔍 Processing question #3...\n⏱️ Generated answer in 8.42 seconds\n\n💡 Answer #3:\n----------------------------------------\nBrand competitiveness is affected by internal factors such as unique features, external image, and regional characteristics, as well as external factors such as market share, brand value creation capability, and competition.\n----------------------------------------\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\n❓ Your question:  quit\n"},{"name":"stdout","text":"\n👋 Thanks for using the Falcon RAG Chatbot! Goodbye!\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport time\nfrom langchain_community.vectorstores import Chroma\nfrom langchain_huggingface import HuggingFaceEmbeddings\nfrom langchain_community.document_loaders import PyPDFLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_huggingface import HuggingFacePipeline\nfrom transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n\n# Step 1: Load and split PDFs\ndef load_pdf_folder(folder_path):\n    start_time = time.time()\n    documents = []\n    for file in os.listdir(folder_path):\n        if file.endswith(\".pdf\"):\n            loader = PyPDFLoader(os.path.join(folder_path, file))\n            documents.extend(loader.load())\n    print(f\"📄 Loaded {len(documents)} documents in {time.time() - start_time:.2f} seconds\")\n    return documents\n\n# Step 2: Split into chunks\ndef split_docs(documents):\n    start_time = time.time()\n    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n    chunks = splitter.split_documents(documents)\n    print(f\"✂️  Split into {len(chunks)} chunks in {time.time() - start_time:.2f} seconds\")\n    return chunks\n\n# Step 3: Embed documents\ndef create_vectorstore(docs):\n    start_time = time.time()\n    embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n    db = Chroma.from_documents(docs, embedding)\n    print(f\"🔍 Created vectorstore in {time.time() - start_time:.2f} seconds\")\n    return db\n\n# Step 4: Load LLaMA Model (GPU-enabled) - OPTIMIZED\ndef load_llama_model(model_id=\"meta-llama/Llama-2-7b-chat-hf\"):\n    start_time = time.time()\n    tokenizer = AutoTokenizer.from_pretrained(model_id)\n    \n    # Load LLaMA with flash attention disabled\n    model = AutoModelForCausalLM.from_pretrained(\n        model_id, \n        device_map=\"auto\", \n        torch_dtype=\"auto\",\n        use_flash_attention_2=False  # Explicitly disable flash attention\n    )\n    \n    # Optimized pipeline settings\n    pipe = pipeline(\n        \"text-generation\", \n        model=model, \n        tokenizer=tokenizer, \n        max_new_tokens=256,  # Reduced from 512 for faster responses\n        do_sample=True,\n        temperature=0.7,\n        top_p=0.9,\n        repetition_penalty=1.1\n    )\n    \n    llm = HuggingFacePipeline(pipeline=pipe)\n    print(f\"🤖 Loaded LLaMA model in {time.time() - start_time:.2f} seconds\")\n    return llm\n\n# Step 5: Answer a question using RAG - OPTIMIZED\ndef ask_question(llm, db, question):\n    start_time = time.time()\n    \n    # Get fewer, more relevant documents\n    relevant_docs = db.similarity_search(question, k=2)  # Reduced from 3 to 2\n    \n    # Clean and truncate context\n    context_parts = []\n    for doc in relevant_docs:\n        # Clean up the text (remove headers, footers, etc.)\n        clean_text = doc.page_content.strip()\n        # Limit each document to 300 characters\n        if len(clean_text) > 300:\n            clean_text = clean_text[:300] + \"...\"\n        context_parts.append(clean_text)\n    \n    context = \"\\n\\n\".join(context_parts)\n    \n    # Optimized prompt for GPT-2\n    prompt = f\"\"\"Based on the following context, provide a concise answer to the question.\n\nContext: {context}\n\nQuestion: {question}\n\nAnswer:\"\"\"\n    \n    response = llm.invoke(prompt)\n    \n    # Clean up the response to extract only the answer\n    response_text = str(response)\n    \n    # Remove the prompt parts from the response\n    if \"Context:\" in response_text:\n        # Find where the actual answer starts\n        answer_start = response_text.find(\"Answer:\")\n        if answer_start != -1:\n            # Extract only the answer part\n            answer = response_text[answer_start + 7:].strip()\n        else:\n            # If we can't find \"Answer:\", just return the last part\n            answer = response_text.split(\"Question:\")[-1].split(\"Answer:\")[-1].strip()\n    else:\n        # If no \"Context:\" found, return the response as is\n        answer = response_text\n    \n    # Clean up any remaining prompt artifacts\n    answer = answer.replace(\"Answer the question using the context below.\", \"\")\n    answer = answer.replace(\"Context:\", \"\").replace(\"Question:\", \"\")\n    answer = answer.strip()\n    \n    print(f\"⏱️  Generated answer in {time.time() - start_time:.2f} seconds\")\n    return answer\n\n# Step 6: Interactive Chatbot - OPTIMIZED\ndef chatbot(llm, db):\n    print(\"\\n\" + \"=\"*80)\n    print(\"🤖 RAG CHATBOT - Ask questions about your documents!\")\n    print(\"💡 Type 'quit' or 'exit' to end the conversation\")\n    print(\"⚡ Optimized for faster responses (max 256 tokens)\")\n    print(\"=\"*80)\n    \n    question_count = 0\n    \n    while True:\n        print(\"\\n\" + \"-\"*50)\n        user_input = input(\"❓ Your question: \").strip()\n        \n        # Check for quit commands\n        if user_input.lower() in ['quit', 'exit', 'q', 'bye']:\n            print(\"\\n👋 Thanks for using the RAG Chatbot! Goodbye!\")\n            break\n        \n        # Check for empty input\n        if not user_input:\n            print(\"⚠️  Please enter a question.\")\n            continue\n        \n        question_count += 1\n        print(f\"\\n🔍 Processing question #{question_count}...\")\n        \n        try:\n            # Get answer\n            answer = ask_question(llm, db, user_input)\n            \n            # Display answer\n            print(f\"\\n💡 Answer #{question_count}:\")\n            print(\"-\" * 40)\n            print(answer)\n            print(\"-\" * 40)\n            \n        except Exception as e:\n            print(f\"❌ Error generating answer: {str(e)}\")\n            print(\"Please try again with a different question.\")\n\n# === MAIN EXECUTION ===\npdf_folder_path = \"/kaggle/input/documents/\"  # <- update this to where your 11 PDFs are\n\nprint(\"🚀 Starting RAG Pipeline...\")\ntotal_start_time = time.time()\n\nprint(\"🔍 Loading PDFs...\")\ndocs = load_pdf_folder(pdf_folder_path)\nchunks = split_docs(docs)\n\nprint(\"📚 Creating vectorstore...\")\ndb = create_vectorstore(chunks)\n\nprint(\"🚀 Loading LLaMA model on GPU...\")\nllm = load_llama_model()\n\nprint(f\"✅ Setup completed in {time.time() - total_start_time:.2f} seconds\")\n\n# Start the interactive chatbot\nchatbot(llm, db)\n\nprint(f\"\\n🎉 Total session time: {time.time() - total_start_time:.2f} seconds\") ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-31T11:31:22.630214Z","iopub.execute_input":"2025-07-31T11:31:22.630476Z","iopub.status.idle":"2025-07-31T11:32:23.560859Z","shell.execute_reply.started":"2025-07-31T11:31:22.630457Z","shell.execute_reply":"2025-07-31T11:32:23.560073Z"}},"outputs":[{"name":"stdout","text":"🚀 Starting RAG Pipeline...\n🔍 Loading PDFs...\n📄 Loaded 153 documents in 9.89 seconds\n✂️  Split into 2103 chunks in 0.05 seconds\n📚 Creating vectorstore...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"🔍 Created vectorstore in 8.04 seconds\n🚀 Loading LLaMA model on GPU...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cc85029f04c45e59068e1fad2c37a92"}},"metadata":{}},{"name":"stdout","text":"🤖 Loaded LLaMA model in 7.04 seconds\n✅ Setup completed in 25.02 seconds\n\n================================================================================\n🤖 RAG CHATBOT - Ask questions about your documents!\n💡 Type 'quit' or 'exit' to end the conversation\n⚡ Optimized for faster responses (max 256 tokens)\n================================================================================\n\n--------------------------------------------------\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"❓ Your question:  What is co-branding? \n"},{"name":"stdout","text":"\n🔍 Processing question #1...\n⏱️  Generated answer in 2.21 seconds\n\n💡 Answer #1:\n----------------------------------------\nAccording to the passage, co-branding is a marketing strategy that involves two or more brands partnering together to create a new product or service offering.\n----------------------------------------\n\n--------------------------------------------------\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"❓ Your question:  What is luxury co-branding?\n"},{"name":"stdout","text":"\n🔍 Processing question #2...\n⏱️  Generated answer in 5.20 seconds\n\n💡 Answer #2:\n----------------------------------------\nLuxury co-branding refers to the strategic partnership or collaboration between a luxury brand and a mass brand to create new products or services that combine the prestige and exclusivity of the luxury brand with the accessibility and affordability of the mass brand. This partnership allows both brands to leverage each other's strengths and resources to create mutually beneficial outcomes.\n----------------------------------------\n\n--------------------------------------------------\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"❓ Your question:  Which factors affect brand competitiveness?\n"},{"name":"stdout","text":"\n🔍 Processing question #3...\n⏱️  Generated answer in 1.82 seconds\n\n💡 Answer #3:\n----------------------------------------\nAccording to scholarly studies, brand competitiveness is affected by various factors including internal features, external image, and regional characteristics.\n----------------------------------------\n\n--------------------------------------------------\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"❓ Your question:  quit\n"},{"name":"stdout","text":"\n👋 Thanks for using the RAG Chatbot! Goodbye!\n\n🎉 Total session time: 60.91 seconds\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}