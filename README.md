## ðŸ“Š Comparative Analysis of Large Language Models in Retrieval-Augmented Generation (RAG) Systems

A comprehensive performance study comparing open-source LLMs for RAG applications, conducted within 15GB GPU memory constraints.

##  Technical Stack

- **LLMs**: HuggingFace Transformers
- **Vector Database**: ChromaDB
- **Embeddings**: sentence-transformers/all-MiniLM-L6-v2
- **Document Processing**: PyPDF, LangChain
- **Environment**: Kaggle (15GB GPU memory)

## Acknowledgments

- HuggingFace for providing the model implementations
- LangChain for the RAG pipeline framework
- ChromaDB for the vector database
- Kaggle for providing the computational resources
